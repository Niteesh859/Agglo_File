{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('myopia.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Size: 463 (74.92%)\n",
      "Validation Data Size: 93 (15.05%)\n",
      "Test Data Size: 62 (10.03%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming your DataFrame is `df`\n",
    "# Step 1: Split into training (75%) and remaining (25%)\n",
    "datatrain, temp_data = train_test_split(df, test_size=0.25, stratify=df['MYOPIC'], random_state=2)\n",
    "\n",
    "# Step 2: Split remaining data (25%) into validation (60% of remaining) and test (40% of remaining)\n",
    "dataval, datatest = train_test_split(temp_data, test_size=0.4, stratify=temp_data['MYOPIC'], random_state=21)\n",
    "\n",
    "x_train = torch.tensor(datatrain[['AGE', 'GENDER', 'DIOPTERHR', 'MOMMY', 'DADMY']].values, dtype=torch.float32)\n",
    "x_val = torch.tensor(dataval[['AGE', 'GENDER', 'DIOPTERHR', 'MOMMY', 'DADMY']].values, dtype=torch.float32)\n",
    "x_test = torch.tensor(datatest[['AGE', 'GENDER', 'DIOPTERHR', 'MOMMY', 'DADMY']].values, dtype=torch.float32)\n",
    "y_train = torch.tensor(datatrain['MYOPIC'].values, dtype=torch.long)\n",
    "y_val = torch.tensor(dataval['MYOPIC'].values, dtype=torch.long)\n",
    "y_test = torch.tensor(datatest['MYOPIC'].values, dtype=torch.long)\n",
    "\n",
    "y_train = F.one_hot(y_train, num_classes=2)\n",
    "y_val = F.one_hot(y_val, num_classes=2)\n",
    "y_test = F.one_hot(y_test, num_classes=2)\n",
    "\n",
    "# Confirm the sizes\n",
    "print(f\"Train Data Size: {len(datatrain)} ({len(datatrain)/len(df)*100:.2f}%)\")\n",
    "print(f\"Validation Data Size: {len(dataval)} ({len(dataval)/len(df)*100:.2f}%)\")\n",
    "print(f\"Test Data Size: {len(datatest)} ({len(datatest)/len(df)*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", 'SPORTHR', 'READHR', 'COMPHR', 'STUDYHR', 'TVHR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "hidden_dims = [5, 5]\n",
    "output_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>STUDYYEAR</th>\n",
       "      <th>MYOPIC</th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>SPHEQ</th>\n",
       "      <th>AL</th>\n",
       "      <th>ACD</th>\n",
       "      <th>LT</th>\n",
       "      <th>VCD</th>\n",
       "      <th>SPORTHR</th>\n",
       "      <th>READHR</th>\n",
       "      <th>COMPHR</th>\n",
       "      <th>STUDYHR</th>\n",
       "      <th>TVHR</th>\n",
       "      <th>DIOPTERHR</th>\n",
       "      <th>MOMMY</th>\n",
       "      <th>DADMY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>21.89</td>\n",
       "      <td>3.690</td>\n",
       "      <td>3.498</td>\n",
       "      <td>14.70</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608</td>\n",
       "      <td>22.38</td>\n",
       "      <td>3.702</td>\n",
       "      <td>3.392</td>\n",
       "      <td>15.29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.179</td>\n",
       "      <td>22.49</td>\n",
       "      <td>3.462</td>\n",
       "      <td>3.514</td>\n",
       "      <td>15.52</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.525</td>\n",
       "      <td>22.20</td>\n",
       "      <td>3.862</td>\n",
       "      <td>3.612</td>\n",
       "      <td>14.73</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697</td>\n",
       "      <td>23.29</td>\n",
       "      <td>3.676</td>\n",
       "      <td>3.454</td>\n",
       "      <td>16.16</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>614</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.678</td>\n",
       "      <td>22.40</td>\n",
       "      <td>3.663</td>\n",
       "      <td>3.803</td>\n",
       "      <td>14.93</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>615</td>\n",
       "      <td>1993</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665</td>\n",
       "      <td>22.50</td>\n",
       "      <td>3.570</td>\n",
       "      <td>3.378</td>\n",
       "      <td>15.56</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>616</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.834</td>\n",
       "      <td>22.94</td>\n",
       "      <td>3.624</td>\n",
       "      <td>3.424</td>\n",
       "      <td>15.89</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>617</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.665</td>\n",
       "      <td>21.92</td>\n",
       "      <td>3.688</td>\n",
       "      <td>3.598</td>\n",
       "      <td>14.64</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>618</td>\n",
       "      <td>1994</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802</td>\n",
       "      <td>22.26</td>\n",
       "      <td>3.530</td>\n",
       "      <td>3.484</td>\n",
       "      <td>15.25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  STUDYYEAR  MYOPIC  AGE  GENDER  SPHEQ     AL    ACD     LT    VCD  \\\n",
       "0      1       1992       1    6       1 -0.052  21.89  3.690  3.498  14.70   \n",
       "1      2       1995       0    6       1  0.608  22.38  3.702  3.392  15.29   \n",
       "2      3       1991       0    6       1  1.179  22.49  3.462  3.514  15.52   \n",
       "3      4       1990       1    6       1  0.525  22.20  3.862  3.612  14.73   \n",
       "4      5       1995       0    5       0  0.697  23.29  3.676  3.454  16.16   \n",
       "..   ...        ...     ...  ...     ...    ...    ...    ...    ...    ...   \n",
       "613  614       1995       1    6       0  0.678  22.40  3.663  3.803  14.93   \n",
       "614  615       1993       0    6       1  0.665  22.50  3.570  3.378  15.56   \n",
       "615  616       1995       0    6       0  1.834  22.94  3.624  3.424  15.89   \n",
       "616  617       1991       0    6       1  0.665  21.92  3.688  3.598  14.64   \n",
       "617  618       1994       0    6       0  0.802  22.26  3.530  3.484  15.25   \n",
       "\n",
       "     SPORTHR  READHR  COMPHR  STUDYHR  TVHR  DIOPTERHR  MOMMY  DADMY  \n",
       "0         45       8       0        0    10         34      1      1  \n",
       "1          4       0       1        1     7         12      1      1  \n",
       "2         14       0       2        0    10         14      0      0  \n",
       "3         18      11       0        0     4         37      0      1  \n",
       "4         14       0       0        0     4          4      1      0  \n",
       "..       ...     ...     ...      ...   ...        ...    ...    ...  \n",
       "613        2       0       7        3    14         37      1      0  \n",
       "614        6       0       1        0     8         10      1      1  \n",
       "615        8       0       0        0     4          4      1      1  \n",
       "616       12       2       1        0    15         23      0      0  \n",
       "617       25       0       2        0    10         14      1      1  \n",
       "\n",
       "[618 rows x 18 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim):\n",
    "        super(Model, self).__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        for h in hidden_dims:\n",
    "            layer = nn.Linear(in_dim, h)\n",
    "            # Initialize weights\n",
    "            nn.init.normal_(layer.weight)\n",
    "            layers.append(layer)\n",
    "            layers.append(nn.ReLU())\n",
    "            in_dim = h\n",
    "        \n",
    "        final_layer = nn.Linear(in_dim, output_dim)\n",
    "        nn.init.normal_(final_layer.weight)\n",
    "        layers.append(final_layer)\n",
    "        \n",
    "        # Final Softmax to get probabilities\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_one_hot(probabilities, one_hot_targets, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    probabilities: (batch_size, num_classes) after softmax\n",
    "    one_hot_targets: (batch_size, num_classes), one-hot encoded\n",
    "    \"\"\"\n",
    "    # Clamp probabilities to avoid log(0)\n",
    "    probs_clamped = torch.clamp(probabilities, min=epsilon, max=1.0 - epsilon)\n",
    "    # Compute cross-entropy\n",
    "    ce = -torch.sum(one_hot_targets * torch.log(probs_clamped), dim=1)\n",
    "    return torch.mean(ce)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, x, y_one_hot):\n",
    "    \"\"\"\n",
    "    x: inputs (batch_size, input_dim)\n",
    "    y_one_hot: one-hot labels (batch_size, num_classes)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(x)  # Already probabilities\n",
    "        # Argmax along dim=1 to get the predicted class index\n",
    "        pred_classes = preds.argmax(dim=1)\n",
    "        # Argmax along dim=1 to get the true class index from one-hot\n",
    "        true_classes = y_one_hot.argmax(dim=1)\n",
    "        acc = (pred_classes == true_classes).float().mean().item()\n",
    "    model.train()\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, \n",
    "                x_train, y_train, \n",
    "                x_val, y_val, \n",
    "                x_test, y_test, \n",
    "                epochs=10, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(x_train)               # shape: (batch_size, 2)\n",
    "        loss = cross_entropy_one_hot(output, y_train)  # y_train is one-hot\n",
    "        \n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute accuracies\n",
    "        train_acc = compute_accuracy(model, x_train, y_train)\n",
    "        val_acc   = compute_accuracy(model, x_val,   y_val)\n",
    "        test_acc  = compute_accuracy(model, x_test,  y_test)\n",
    "        \n",
    "        tqdm.write(\n",
    "            f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"Loss: {loss.item():.4f} | \"\n",
    "            f\"Train Acc: {train_acc:.4f} | \"\n",
    "            f\"Val Acc: {val_acc:.4f} | \"\n",
    "            f\"Test Acc: {test_acc:.4f}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=5, out_features=5, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=5, out_features=2, bias=True)\n",
       "    (5): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = Model(input_dim = input_dim, hidden_dims = hidden_dims, output_dim = output_dim)\n",
    "model0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10/10 [00:00<00:00, 169.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 2.0179 | Train Acc: 0.2916 | Val Acc: 0.2151 | Test Acc: 0.2258\n",
      "Epoch 2/10 | Loss: 0.6946 | Train Acc: 0.8683 | Val Acc: 0.8710 | Test Acc: 0.8710\n",
      "Epoch 3/10 | Loss: 0.5875 | Train Acc: 0.8683 | Val Acc: 0.8710 | Test Acc: 0.8710\n",
      "Epoch 4/10 | Loss: 0.6544 | Train Acc: 0.8683 | Val Acc: 0.8710 | Test Acc: 0.8710\n",
      "Epoch 5/10 | Loss: 0.4785 | Train Acc: 0.8575 | Val Acc: 0.8602 | Test Acc: 0.8710\n",
      "Epoch 6/10 | Loss: 0.4906 | Train Acc: 0.8618 | Val Acc: 0.8602 | Test Acc: 0.8710\n",
      "Epoch 7/10 | Loss: 0.4463 | Train Acc: 0.8683 | Val Acc: 0.8710 | Test Acc: 0.8710\n",
      "Epoch 8/10 | Loss: 0.4145 | Train Acc: 0.8251 | Val Acc: 0.8495 | Test Acc: 0.7903\n",
      "Epoch 9/10 | Loss: 0.4346 | Train Acc: 0.8683 | Val Acc: 0.8710 | Test Acc: 0.8710\n",
      "Epoch 10/10 | Loss: 0.3914 | Train Acc: 0.8683 | Val Acc: 0.8710 | Test Acc: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model0, x_train, y_train, x_val, y_val, x_test, y_test, epochs=10, lr=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: tensor([[0.8717, 0.1283]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Original input (dtype = long, shape = [5])\n",
    "input_long = torch.tensor([7, 1, 9, 0, 1]).long()\n",
    "\n",
    "# 1. Convert to float32\n",
    "# 2. Add a batch dimension at the beginning (so shape is [1, 5])\n",
    "input_float = input_long.unsqueeze(0).float()  # shape: (1, 5)\n",
    "\n",
    "# Pass it through the model\n",
    "output = model0(input_float)\n",
    "print(\"Model output:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model0.state_dict(), \"model0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred: HTTPConnectionPool(host='127.0.0.1', port=5000): Max retries exceeded with url: /survey (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000028FCBA6EDD0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# # Backend API URL\n",
    "# url = \"http://127.0.0.1:5000/survey\"  # Replace 'endpoint' with your actual route\n",
    "\n",
    "# try:\n",
    "#     # Make a GET request\n",
    "#     response = requests.get(url)\n",
    "\n",
    "#     # Check if the request was successful\n",
    "#     if response.status_code == 200:\n",
    "#         # Parse the JSON response\n",
    "#         data1 = response.json()\n",
    "#         print(\"Data fetched successfully:\", data1)\n",
    "#     else:\n",
    "#         print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "#         print(\"Response:\", response.text)\n",
    "# except Exception as e:\n",
    "#     print(\"Error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'survey': [{'age': 5,\n",
       "   'dad': 1,\n",
       "   'gender': 'Male',\n",
       "   'id': 1,\n",
       "   'mom': 1,\n",
       "   'name': 'Niteesh',\n",
       "   'time_reading': 53,\n",
       "   'time_sports': 21,\n",
       "   'time_studying': 342,\n",
       "   'time_tv': 54,\n",
       "   'time_video_games': 564}]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
